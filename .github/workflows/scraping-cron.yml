name: Scraping Automático

on:
  schedule:
    # Executa a cada 6 horas (00:00, 06:00, 12:00, 18:00 UTC)
    # UTC -3 = Horário de Brasília: 21:00, 03:00, 09:00, 15:00
    - cron: '0 */6 * * *'
  workflow_dispatch: # Permite execução manual via interface do GitHub

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Install Chrome dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
      
      - name: Validar configuração
        run: |
          if [ -z "${{ secrets.VERCEL_URL }}" ]; then
            echo "❌ VERCEL_URL não configurado!"
            echo "Configure o secret VERCEL_URL com: https://www.ybybid.com.br"
            exit 1
          fi
          
          if [ -z "${{ secrets.CRON_SECRET }}" ]; then
            echo "❌ CRON_SECRET não configurado!"
            exit 1
          fi
          
          echo "✅ URL: ${{ secrets.VERCEL_URL }}/api/cron/scrape"
          echo "✅ Secrets configurados corretamente"

      - name: Executar scraping de veículos
        env:
          CHROME_PATH: /usr/bin/google-chrome-stable
        run: |
          response=$(curl -L -s -w "\n%{http_code}" -X POST \
            ${{ secrets.VERCEL_URL }}/api/cron/scrape \
            -H "Authorization: Bearer ${{ secrets.CRON_SECRET }}" \
            -H "Content-Type: application/json")
          
          http_code=$(echo "$response" | tail -n1)
          body=$(echo "$response" | sed '$d')
          
          echo "Status HTTP: $http_code"
          echo "Resposta: $body"
          
          if [ "$http_code" -ne 200 ]; then
            echo "❌ Erro ao executar scraping!"
            echo "Status HTTP: $http_code"
            echo "URL chamada: ${{ secrets.VERCEL_URL }}/api/cron/scrape"
            echo "Resposta completa:"
            echo "$body"
            exit 1
          fi
          
          echo "✅ Scraping executado com sucesso!"

      - name: Notificar falha
        if: failure()
        run: |
          echo "❌ Scraping falhou. Verifique os logs acima."

